{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fake News Detector - Realtime Inference\n",
        "The notebook covers the Realtime Inference workflow run on the model build on ISOT Fake News detection dataset, provided by Kaggle.\n",
        "\n",
        "The Kaggle Link : https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset"
      ],
      "metadata": {
        "id": "DWk_4RIO05cX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJUHTdJp0s_v",
        "outputId": "ecf1a44a-5ea2-42de-aba5-8e6e085367a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install required packages\n",
        "!pip install pandas --quiet\n",
        "!python -m nltk.downloader punkt_tab wordnet stopwords > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fDb_cqajqrVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import joblib"
      ],
      "metadata": {
        "id": "NrkR2evb1rBK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process individual text entries"
      ],
      "metadata": {
        "id": "U5Kqlfsu2o4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove special characters/numbers except basic punctuation\n",
        "    text = re.sub(r'[^a-zA-Z\\s.,!?]', '', text)\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords and lemmatize\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Remove short words (length < 2)\n",
        "    tokens = [word for word in tokens if len(word) > 1]\n",
        "\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "Zp5xwKIV2vTw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the model"
      ],
      "metadata": {
        "id": "VtbRgdg1rY23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = joblib.load(\"fake_news_model.pkl\")"
      ],
      "metadata": {
        "id": "hdEDrXGYrfJn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction workflow"
      ],
      "metadata": {
        "id": "Gg-fZLearnG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(title, text):\n",
        "    if not isinstance(title, str) or not isinstance(text, str):\n",
        "        return {\n",
        "            \"label\": \"Invalid\",\n",
        "            \"confidence\": \"0%\",\n",
        "            \"error\": \"Both title and text must be strings.\"\n",
        "        }\n",
        "\n",
        "    combined = f\"{title.strip()} {text.strip()}\".strip()\n",
        "\n",
        "    if not combined:\n",
        "        return {\n",
        "            \"label\": \"Invalid\",\n",
        "            \"confidence\": \"0%\",\n",
        "            \"error\": \"Combined input is empty after stripping.\"\n",
        "        }\n",
        "\n",
        "    processed = preprocess_text(combined)\n",
        "    if not processed:\n",
        "        return {\n",
        "            \"label\": \"Invalid\",\n",
        "            \"confidence\": \"0%\",\n",
        "            \"error\": \"Text could not be processed meaningfully.\"\n",
        "        }\n",
        "\n",
        "    pred = model.predict([processed])[0]\n",
        "    proba = model.predict_proba([processed])[0]\n",
        "\n",
        "    return {\n",
        "        \"label\": \"Fake\" if pred == 1 else \"Real\",\n",
        "        \"confidence\": f\"{max(proba) * 100:.2f}%\",\n",
        "        \"probabilities\": {\n",
        "            \"Real\": round(proba[0], 4),\n",
        "            \"Fake\": round(proba[1], 4)\n",
        "        }\n",
        "    }"
      ],
      "metadata": {
        "id": "mg9DGYQtrr_A"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test run"
      ],
      "metadata": {
        "id": "WYWYHiU2rzCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    sample_title = \"NASA confirms\"\n",
        "    sample_text = \"moon base construction starts in 2026.\"\n",
        "    result = predict(sample_title, sample_text)\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVCGdzbQr1L4",
        "outputId": "31896f09-61ed-4108-f137-0a1f5bea2793"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 'Fake', 'confidence': '58.23%', 'probabilities': {'Real': np.float64(0.4177), 'Fake': np.float64(0.5823)}}\n"
          ]
        }
      ]
    }
  ]
}